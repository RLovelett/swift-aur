From b680446ba6906f884ebe5e3b345bbb16f16e112c Mon Sep 17 00:00:00 2001
From: Ryan Lovelett <ryan@lovelett.me>
Date: Mon, 28 Dec 2015 10:13:48 -0500
Subject: [PATCH 1/6] [gyb] Use partial function application to work around PEP
 3114

[PEP 3114](https://www.python.org/dev/peps/pep-3114/) renamed
`iterator.next()` (Python 2) to `iterator.__next__()` (Python 3). The
recommended solution to make the code work in both Python 2 and 3 is to
call the global `next` function.

To use this recommended global `next` function this patch uses partial
function application to fix the iterator as an argument to the global
`next` function. This new function is then sent to
`tokenize.generate_tokens` as it was previously.

This should be functionally equivalent to the old code with the added
benefit of working on both Python 2 and 3.

**NOTE**: There are still other Python 3 fixes necessary to make `gyb`
run on a Python 3 interpreter. This is just one small incremental patch
on the way there.
---
 utils/gyb.py | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/utils/gyb.py b/utils/gyb.py
index 0d12317..4e98ced 100755
--- a/utils/gyb.py
+++ b/utils/gyb.py
@@ -10,6 +10,7 @@ import tokenize
 import textwrap
 from bisect import bisect
 import os
+from functools import partial
 
 def getLineStarts(s):
     """Return a list containing the start index of each line in s.
@@ -304,7 +305,7 @@ def splitGybLines(sourceLines):
     dedents = 0
     try:
         for tokenKind, tokenText, tokenStart, (tokenEndLine, tokenEndCol), lineText \
-            in tokenize.generate_tokens(sourceLines.__iter__().next):
+            in tokenize.generate_tokens(partial(next, sourceLines.__iter__())):
 
             if tokenKind in (tokenize.COMMENT, tokenize.ENDMARKER): 
                 continue
@@ -347,7 +348,7 @@ def codeStartsWithDedentKeyword(sourceLines):
     """
     tokenText = None
     for tokenKind, tokenText, _, _, _ \
-        in tokenize.generate_tokens(sourceLines.__iter__().next):
+        in tokenize.generate_tokens(partial(next, sourceLines.__iter__())):
 
         if tokenKind != tokenize.COMMENT and tokenText.strip() != '':
             break
-- 
2.6.4

